import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

def get_data():
    seed = 30
    return [
        datasets.make_circles(n_samples=500, factor=0.5, noise=0.05, random_state=seed),
        datasets.make_moons(n_samples=500, noise=0.05, random_state=seed),
        datasets.make_blobs(n_samples=500, cluster_std=[1.0, 0.5], random_state=seed, centers=2)
    ]

def plot_results(ax, model, X, y):
 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    

    model.fit(X_train, y_train)
    
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))

    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)
    ax.contourf(xx, yy, Z, alpha=0.3)
    
    y_pred = model.predict(X_test)
    colors = ['red' if y_test[i] != y_pred[i] else 'blue' for i in range(len(y_test))]
    ax.scatter(X_test[:, 0], X_test[:, 1], c=colors, s=10)


data = get_data()
models = [
    ('KNN', KNeighborsClassifier(n_neighbors=5)),
    ('SVM', SVC(kernel='rbf')),
    ('LogReg', LogisticRegression())
]

fig, axs = plt.subplots(3, 3, figsize=(10, 8))
for i, (X, y) in enumerate(data):
    for j, (name, model) in enumerate(models):
        plot_results(axs[i,j], model, X, y)
        if i == 0:
            axs[i,j].set_title(name)
plt.tight_layout()
plt.show()
